{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de343f80-eb4c-4e88-b01a-7ca497ccd6b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from src.gen.util import read_gzip_data, write_gzip_data\n",
    "\n",
    "datap = Path(\"/users/k21190024/study/fact-check-transfer-learning/scratch/dumps/data/level/2\")\n",
    "dumpp = Path(\"/users/k21190024/study/fact-check-transfer-learning/scratch/dumps/explore/level/2\")\n",
    "if not dumpp.exists():\n",
    "    dumpp.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dec321-6c2f-49b3-a43b-ed1db7dc5512",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85f1535e-eee6-4cbc-b24f-bc6e621c1802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cla = \"claims_lemma.pkl.gz\"\n",
    "cor = \"corpus_lemma.pkl.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a179365a-fe8e-4855-aabe-33c41c374f14",
   "metadata": {},
   "source": [
    "# Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fff3aae1-f63f-48e2-8a03-7bd74175829c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fls = [\n",
    "    datap.joinpath(\"scifact\", cla), datap.joinpath(\"scifact\", cor)\n",
    "    , datap.joinpath(\"fever\", cla), datap.joinpath(\"fever\", cor)\n",
    "    , datap.joinpath(\"climatefever\", cla), datap.joinpath(\"climatefever\", cor)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e27e4c-58ca-4cf5-a084-cac88710e3d8",
   "metadata": {},
   "source": [
    "## Lemma per doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fac3ec84-97dc-426f-88cd-f72afd14f311",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scifact-claims-claims</td>\n",
       "      <td>1409.000000</td>\n",
       "      <td>1409.0</td>\n",
       "      <td>1409</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scifact-corpus-title</td>\n",
       "      <td>5183.000000</td>\n",
       "      <td>5183.0</td>\n",
       "      <td>5183</td>\n",
       "      <td>5183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scifact-corpus-evidence</td>\n",
       "      <td>5183.000000</td>\n",
       "      <td>5183.0</td>\n",
       "      <td>5183</td>\n",
       "      <td>5183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fever-claims-claims</td>\n",
       "      <td>185445.000000</td>\n",
       "      <td>185445.0</td>\n",
       "      <td>185445</td>\n",
       "      <td>185445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fever-corpus</td>\n",
       "      <td>48.791444</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>93907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>climatefever-claims-claims</td>\n",
       "      <td>1535.000000</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>1535</td>\n",
       "      <td>1535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>climatefever-corpus-title</td>\n",
       "      <td>1535.000000</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>1535</td>\n",
       "      <td>1535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>climatefever-corpus-evidence</td>\n",
       "      <td>7675.000000</td>\n",
       "      <td>7675.0</td>\n",
       "      <td>7675</td>\n",
       "      <td>7675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        dataset           mean    median     min     max\n",
       "0         scifact-claims-claims    1409.000000    1409.0    1409    1409\n",
       "1          scifact-corpus-title    5183.000000    5183.0    5183    5183\n",
       "2       scifact-corpus-evidence    5183.000000    5183.0    5183    5183\n",
       "3           fever-claims-claims  185445.000000  185445.0  185445  185445\n",
       "4                  fever-corpus      48.791444      32.0       0   93907\n",
       "5    climatefever-claims-claims    1535.000000    1535.0    1535    1535\n",
       "6     climatefever-corpus-title    1535.000000    1535.0    1535    1535\n",
       "7  climatefever-corpus-evidence    7675.000000    7675.0    7675    7675"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemma_per_doc(fp):\n",
    "    ls = read_gzip_data(fp)\n",
    "    res = []\n",
    "    \n",
    "    if isinstance(ls, list):\n",
    "        res.append((f\"{fp.parent.name}-{fp.name.split('_')[0]}\", [len(l) for l in ls]))\n",
    "    elif isinstance(ls, dict):\n",
    "        for k, v in ls.items():\n",
    "            if k == \"ner\":\n",
    "                continue\n",
    "            res.append((f\"{fp.parent.name}-{fp.name.split('_')[0]}-{k}\", [len(l) for l in v]))\n",
    "    return res\n",
    "\n",
    "res_ls = Parallel(n_jobs=len(fls))(delayed(lemma_per_doc)(fp) for fp in fls)\n",
    "\n",
    "lemmapd = []\n",
    "for r in res_ls:\n",
    "    tmp = {}\n",
    "    for doc, lemmas in r:\n",
    "        lemmapd.append({\n",
    "            \"dataset\": doc,\n",
    "            \"mean\": np.mean(lemmas),\n",
    "            \"median\": np.median(lemmas),\n",
    "            \"min\": np.min(lemmas),\n",
    "            \"max\": np.max(lemmas),\n",
    "        })\n",
    "df_lempd = pd.DataFrame(lemmapd)\n",
    "df_lempd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d01127d-e11c-4ff2-adfb-a4a8b6531b50",
   "metadata": {},
   "source": [
    "## Lemma histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97a9fb18-e53b-4590-ad08-f48bffb35682",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/scratch/users/k21190024/envs/p-dis-tf/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 428, in _process_worker\n    r = call_item()\n  File \"/scratch/users/k21190024/envs/p-dis-tf/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/scratch/users/k21190024/envs/p-dis-tf/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n  File \"/scratch/users/k21190024/envs/p-dis-tf/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n  File \"/scratch/users/k21190024/envs/p-dis-tf/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/tmp/slurm-tmp.1592607/ipykernel_1458513/3495995527.py\", line 17, in count_words\n  File \"/software/spackages_prod/apps/linux-ubuntu20.04-zen2/gcc-9.4.0/python-3.8.12-mdneme5mnx2ihlvy6ihbvjatdvnn45l6/lib/python3.8/collections/__init__.py\", line 552, in __init__\n    self.update(iterable, **kwds)\n  File \"/software/spackages_prod/apps/linux-ubuntu20.04-zen2/gcc-9.4.0/python-3.8.12-mdneme5mnx2ihlvy6ihbvjatdvnn45l6/lib/python3.8/collections/__init__.py\", line 637, in update\n    _count_elements(self, iterable)\nTypeError: unhashable type: 'list'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m     countwords \u001b[38;5;241m=\u001b[39m read_gzip_data(dumpp\u001b[38;5;241m.\u001b[39mjoinpath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount_lemma.pkl.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m     res_ls \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcount_words\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfls\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     countwords \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m res_ls:\n",
      "File \u001b[0;32m/scratch/users/k21190024/envs/p-dis-tf/lib/python3.8/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m/scratch/users/k21190024/envs/p-dis-tf/lib/python3.8/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m/scratch/users/k21190024/envs/p-dis-tf/lib/python3.8/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/software/spackages_prod/apps/linux-ubuntu20.04-zen2/gcc-9.4.0/python-3.8.12-mdneme5mnx2ihlvy6ihbvjatdvnn45l6/lib/python3.8/concurrent/futures/_base.py:444\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/software/spackages_prod/apps/linux-ubuntu20.04-zen2/gcc-9.4.0/python-3.8.12-mdneme5mnx2ihlvy6ihbvjatdvnn45l6/lib/python3.8/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "def count_words(fp):\n",
    "    ls = read_gzip_data(fp)\n",
    "    res = []\n",
    "    \n",
    "    if isinstance(ls, list):\n",
    "        flatls = []\n",
    "        for i in ls:\n",
    "            flatls += i\n",
    "        res.append((f\"{fp.parent.name}-{fp.name.split('_')[0]}\", Counter(flatls)))\n",
    "    elif isinstance(ls, dict):\n",
    "        for k, v in ls.items():\n",
    "            if k == \"ner\":\n",
    "                continue\n",
    "            flatls = []\n",
    "            for i in v:\n",
    "                flatls += i\n",
    "            res.append((f\"{fp.parent.name}-{fp.name.split('_')[0]}-{k}\", Counter(flatls)))\n",
    "    return res\n",
    "\n",
    "if dumpp.joinpath(\"count_lemma.pkl.gz\").exists():\n",
    "    countwords = read_gzip_data(dumpp.joinpath(\"count_lemma.pkl.gz\"))\n",
    "else:\n",
    "    res_ls = Parallel(n_jobs=len(fls))(delayed(count_words)(fp) for fp in fls)\n",
    "    countwords = []\n",
    "    for r in res_ls:\n",
    "        countwords += r\n",
    "\n",
    "    write_gzip_data(dumpp.joinpath(\"count_lemma.pkl.gz\"), countwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf82f77-2e56-4f52-9cdb-7fbb2d4939fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_words = pd.DataFrame(columns=[\"dataset\", \"lemma\", \"count\"])\n",
    "for k, v in countwords:\n",
    "    tv = dict(v)\n",
    "    tmpdf = pd.DataFrame(list(tv.items()), columns=[\"lemma\", \"count\"])\n",
    "    tmpdf[\"dataset\"] = k\n",
    "    df_words = pd.concat([df_words, tmpdf], axis=0)\n",
    "df_words = df_words.reset_index(drop=True)\n",
    "df_words = df_words.merge(df_words.groupby(\"dataset\", as_index=False)[\"count\"].sum().rename({\"count\": \"total_count\"}, axis=1), on=\"dataset\")\n",
    "df_words[\"normalised_count\"] = df_words[\"count\"] / df_words[\"total_count\"] * 100\n",
    "df_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d1b199-f035-41d3-9bb5-6ec1ce4818fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_topwords = (\n",
    "    df_words\n",
    "    .sort_values([\"dataset\", \"count\"], ascending=[True, False])\n",
    "    .groupby(\"dataset\", as_index=False)\n",
    "    .head(10)\n",
    ")\n",
    "df_topwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068ff5af-b82d-4016-bb70-6fd2fc2f922c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = sns.catplot(x=\"lemma\", y=\"normalised_count\", data=df_topwords[df_topwords[\"dataset\"].str.contains(\"climate\")], col=\"dataset\", kind=\"bar\", facet_kws={'sharey': False, 'sharex': False})\n",
    "g.set_xticklabels(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10bdf7d-5d7e-4dc7-8176-4e8570831e72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = sns.catplot(x=\"lemma\", y=\"normalised_count\", data=df_topwords.loc[(df_topwords[\"dataset\"].str.contains(\"fever\") & (~df_topwords[\"dataset\"].str.contains(\"climate\")))], col=\"dataset\", kind=\"bar\", facet_kws={'sharey': False, 'sharex': False})\n",
    "g.set_xticklabels(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec551c6a-a2b5-4d37-a635-040471a4169f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = sns.catplot(x=\"lemma\", y=\"normalised_count\", data=df_topwords[df_topwords[\"dataset\"].str.contains(\"scifact\")], col=\"dataset\", kind=\"bar\", facet_kws={'sharey': False, 'sharex': False})\n",
    "g.set_xticklabels(rotation=45)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
