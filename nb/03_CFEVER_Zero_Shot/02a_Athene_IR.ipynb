{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb789185-a1cb-4848-8e1f-56d195bde300",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e19e27-b4b4-4f93-b2b9-e941598aa23b",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6d31b4f-3fe5-4502-9100-df2514109098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../src\")\n",
    "\n",
    "import json\n",
    "import random\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import scipy\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import constants\n",
    "from evaluate import score\n",
    "from gen.util import read_data, write_jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380499e8-90d0-4ddc-b6a8-7aa91cc7bf79",
   "metadata": {},
   "source": [
    "# FEVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29677836-e732-4e84-ad75-4ef88338b7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fever_actual = Path(\"/users/k21190024/study/fact-checking-repos/fever/teamathene/data/fever-data\")\n",
    "fever_train_actual = read_data(fever_actual / \"train.jsonl\")\n",
    "fever_dev_actual = read_data(fever_actual / \"dev.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e8af4a-feb3-4a86-9382-91240b3da41d",
   "metadata": {},
   "source": [
    "## IR Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e11d04fe-1d49-4987-86bd-db35cd070a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "fever_pages = Path(\"/users/k21190024/study/fact-checking-repos/fever/teamathene/data/fever\")\n",
    "fever_train = read_data(fever_pages / \"train.p7.s5.jsonl\")\n",
    "fever_dev = read_data(fever_pages / \"dev.p7.s5.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38bce83a-7116-4cf1-8fbf-146605498c02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            FEVER train\n",
      "            Oracle IR: False\n",
      "            Oracle RTE: True\n",
      "            Max Evidences: None\n",
      "\n",
      "            FEVER Score: 90.3\n",
      "            Accuracy: 100.0\n",
      "            Macro Precision: 26.1\n",
      "            Macro Recall: 87.16\n",
      "            Macro F1: 40.18\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "fever_train_scored = score.FEVERScorer(fever_train_actual, fever_train, oracle_ir=False, oracle_rte=True, max_evidence=None, score_name=\"FEVER train\")\n",
    "print(fever_train_scored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "176b0c72-d769-485d-9fa0-a49a9110f020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': 0.8963470421138264, 'precision': 0.32361337977789684}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fever_train_scored.get_document_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77b61d2b-f6d1-4e55-b1ba-ba0358d98796",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            FEVER Dev\n",
      "            Oracle IR: False\n",
      "            Oracle RTE: True\n",
      "            Max Evidences: None\n",
      "\n",
      "            FEVER Score: 90.68\n",
      "            Accuracy: 100.0\n",
      "            Macro Precision: 23.81\n",
      "            Macro Recall: 86.03\n",
      "            Macro F1: 37.3\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "fever_dev_scored = score.FEVERScorer(fever_dev_actual, fever_dev, oracle_ir=False, oracle_rte=True, max_evidence=None, score_name=\"FEVER Dev\")\n",
    "print(fever_dev_scored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1fbc237-0cc3-4e3d-9305-752b55d0489b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': 0.9044265668449961, 'precision': 0.3068520285351291}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fever_dev_scored.get_document_metric()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c40cb3-7ddf-4385-a062-2d999a6d982a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Climate-FEVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d8a29db-7347-4e69-8745-a4f3359d1579",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfever_actual = Path(\"/users/k21190024/study/fact-checking-repos/fever/teamathene/data/cfever-data\")\n",
    "cfever_train_actual = read_data(cfever_actual / \"train.jsonl\")\n",
    "cfever_dev_actual = read_data(cfever_actual / \"dev.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8ef5cf-8654-41b9-b232-43f24e65920a",
   "metadata": {},
   "source": [
    "## IR Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9c0c9c7-fd8e-479c-b3e5-228825117444",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfever_pages = Path(\"/users/k21190024/study/fact-checking-repos/fever/teamathene/data/climatefever\")\n",
    "cfever_train = read_data(cfever_pages / \"train.p7.s5.jsonl\")\n",
    "cfever_dev = read_data(cfever_pages / \"dev.p7.s5.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d046aaac-9bb2-487c-996f-d7ca1f8b5724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            Climate-FEVER Train\n",
      "            Oracle IR: False\n",
      "            Oracle RTE: True\n",
      "            Max Evidences: None\n",
      "\n",
      "            FEVER Score: 24.22\n",
      "            Accuracy: 100.0\n",
      "            Macro Precision: 11.24\n",
      "            Macro Recall: 24.22\n",
      "            Macro F1: 15.36\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "cfever_train_scored = score.ClimateFEVERScorer(cfever_train_actual, cfever_train, oracle_ir=False, oracle_rte=True, max_evidence=None, score_name=\"Climate-FEVER Train\")\n",
    "print(cfever_train_scored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf0b25f4-22ec-446a-8dbb-292de335de4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': 0.18693926846100758, 'precision': 0.08108311141557731}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfever_train_scored.get_document_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f13a2d4a-4ac5-450d-b605-369a41757b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            Climate-FEVER Dev\n",
      "            Oracle IR: False\n",
      "            Oracle RTE: True\n",
      "            Max Evidences: None\n",
      "\n",
      "            FEVER Score: 22.66\n",
      "            Accuracy: 100.0\n",
      "            Macro Precision: 10.31\n",
      "            Macro Recall: 22.66\n",
      "            Macro F1: 14.17\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "cfever_dev_scored = score.ClimateFEVERScorer(cfever_dev_actual, cfever_dev, oracle_ir=False, oracle_rte=True, max_evidence=None, score_name=\"Climate-FEVER Dev\")\n",
    "print(cfever_dev_scored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "578623c7-457e-4aa0-89d9-7b94f9dbeaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': 0.2223021582733813, 'precision': 0.09046754544045565}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfever_dev_scored.get_document_metric()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152e5456-cfa7-498c-88cc-b49f86569edd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SciFact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "078ca427-8a9e-40c8-a357-46a9f57edd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_actual_p = Path(\"/users/k21190024/study/fact-checking-repos/fever/teamathene/data/scifact-data\")\n",
    "sf_actual = read_data(sf_actual_p / \"scifact_all_titleid.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d9d20b-8284-4433-8d55-4f437198f58d",
   "metadata": {},
   "source": [
    "## IR Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47562781-f2ef-447b-9fd3-ba0f996ae1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_pages = Path(\"/users/k21190024/study/fact-checking-repos/fever/teamathene/data/scifact\")\n",
    "sf_all = read_data(sf_pages / \"test.p7.s5.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94bf3b21-2022-44ed-b18f-1c06da406479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            SciFact All\n",
      "            Oracle IR: False\n",
      "            Oracle RTE: True\n",
      "            Max Evidences: None\n",
      "\n",
      "            FEVER Score: 37.51\n",
      "            Accuracy: 100.0\n",
      "            Macro Precision: 5.19\n",
      "            Macro Recall: 0.0\n",
      "            Macro F1: 0.0\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "sf_scored = score.FEVERScorer(sf_actual, sf_all, oracle_ir=False, oracle_rte=True, max_evidence=None, score_name=\"SciFact All\")\n",
    "print(sf_scored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f29209c-3b8c-4eb7-95dd-e752c651c8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': 0.0, 'precision': 0.0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_scored.get_document_metric()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
