{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c83b33f3-017c-41b4-acec-65ae552b1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../src\")\n",
    "import re\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import constants\n",
    "from rte.aggregate import agg_predict_proba, agg_predict\n",
    "from gen.util import read_data, write_jsonl\n",
    "from gen.special import entropy3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6f9d59-9944-4486-accb-8718606d4a18",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdda4264-4347-4e68-9fdf-bf5c8d247d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_p = Path(\"/users/k21190024/study/fact-check-transfer-learning/scratch/thesis/errors/scifact/sentence\")\n",
    "sent_pls = Path(\"/users/k21190024/study/fact-check-transfer-learning/scratch/thesis/predictions/sent/scifact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14d054e5-a8c3-40fd-850d-66c23af1c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_predictions(fn):\n",
    "    df = pd.DataFrame(read_data(fn))\n",
    "    rnd = partial(np.round, decimals=4)\n",
    "    df = df.assign(\n",
    "        predicted_label=df[\"predicted_label\"].map(constants.LABEL2ID),\n",
    "        predicted_proba=df[\"predicted_proba\"].apply(rnd).apply(lambda x: x.tolist())\n",
    "    )\n",
    "    \n",
    "    get_proba = partial(agg_predict_proba, return_proba=True)\n",
    "    df_mean = (\n",
    "        df\n",
    "        .groupby(\"claim_id\", sort=False)[[\"predicted_proba\"]]\n",
    "        .agg({\"predicted_proba\": get_proba})\n",
    "        .rename(columns={\"predicted_proba\": \"mean_proba\"})\n",
    "    )\n",
    "    df_mean[\"mean_proba\"] = df_mean[\"mean_proba\"].apply(rnd).apply(lambda x: x.tolist())\n",
    "    df_grp = (\n",
    "        df\n",
    "        .groupby(\"claim_id\", sort=False)\n",
    "        .agg({\"predicted_label\": list, \"predicted_proba\": list})\n",
    "        .join(df_mean, how=\"inner\")\n",
    "    )\n",
    "    \n",
    "    \n",
    "    tok = fn.stem.split(\".\")[0].split(\"-\")\n",
    "    dataset = \"-\".join([tok[0], tok[1] if \"climatefever\" in tok[1] else \"\"]).strip(\"-\")\n",
    "    model = fn.stem.split(\".\")[0].strip(dataset).strip(\"-\")\n",
    "    df_grp[\"score_name\"] = fn.stem.split(\".\")[0]\n",
    "    df_grp[\"dataset\"] = dataset\n",
    "    df_grp[\"model\"] = model\n",
    "    \n",
    "    return df_grp.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb7ade4a-6b53-4c75-ba44-c688499173c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = Parallel()(delayed(preprocess_predictions)(p) for p in sent_pls.iterdir())\n",
    "df_sent_all = pd.concat(res, axis=0).rename(columns={\"claim_id\": \"id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c98f04f-6bd3-4803-b6df-db2b902e6d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_with_preds(fn, df_sent):\n",
    "    agg_type = fn.stem.split(\"_\")[0]\n",
    "    dataset = re.findall(\".*_disagree_(.*)_total.*\", fn.stem)[0]\n",
    "    \n",
    "    error_f = read_data(fn)\n",
    "    if \"mean_proba\" in error_f[0] or \"predicted_label\" in error_f[0]:\n",
    "        return\n",
    "    \n",
    "    df_filter = (\n",
    "        df_sent\n",
    "        .set_index(\"id\")\n",
    "        .loc[pd.Index([doc[\"id\"] for doc in error_f], name=\"id\")]\n",
    "    )\n",
    "    if dataset != \"alltrain\":\n",
    "        df_filter = df_filter.query(f\"dataset == '{dataset}'\")\n",
    "        \n",
    "    all_models = sorted(df_sent[\"model\"].unique())\n",
    "    cols = [\"model\", \"dataset\"] + ([\"predicted_label\"] if agg_type == \"majority\" else [\"predicted_proba\", \"mean_proba\"])\n",
    "    df_filter = df_filter[cols]\n",
    "    res = {}\n",
    "    for bert, xlnet in zip(df_filter.query(f\"model == '{all_models[0]}'\").iterrows(), df_filter.query(f\"model == '{all_models[1]}'\").iterrows()):\n",
    "        assert bert[0] == xlnet[0]\n",
    "        sfid = bert[0]\n",
    "        if sfid not in res:\n",
    "            res[sfid] = {}\n",
    "        if dataset == \"alltrain\":\n",
    "            for c in cols[2:]:\n",
    "                if c not in res[sfid]:\n",
    "                    res[sfid][c] = {}\n",
    "                if bert[1][cols[1]] not in res[sfid][c]:\n",
    "                    res[sfid][c][bert[1][cols[1]]] = {bert[1].model.split(\"-\")[0]: bert[1][c]}\n",
    "                else:\n",
    "                    res[sfid][c][bert[1][cols[1]]].update({bert[1].model.split(\"-\")[0]: bert[1][c]})\n",
    "                if xlnet[1][cols[1]] not in res[sfid][c]:\n",
    "                    res[sfid][c][xlnet[1][cols[1]]] = {xlnet[1].model.split(\"-\")[0]: xlnet[1][c]}\n",
    "                else:\n",
    "                    res[sfid][c][xlnet[1][cols[1]]].update({xlnet[1].model.split(\"-\")[0]: xlnet[1][c]})\n",
    "        else:\n",
    "            for c in cols[2:]:\n",
    "                res[sfid].update({\n",
    "                    c: {\n",
    "                        bert[1].model.split(\"-\")[0]: bert[1][c],\n",
    "                        xlnet[1].model.split(\"-\")[0]: xlnet[1][c]\n",
    "                    }\n",
    "                })\n",
    "    if dataset == \"alltrain\":\n",
    "        res = {k: {kk: dict(sorted(vv.items())) for kk, vv in v.items()} for k, v in res.items()}\n",
    "    error_f = pd.DataFrame(error_f).set_index(\"id\").join(pd.DataFrame(res).T, how=\"left\").reset_index()\n",
    "\n",
    "    return write_jsonl(fn, error_f.to_dict(\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "647c2946-bcd0-4b3e-b45c-8fed0608a4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = Parallel()(delayed(update_with_preds)(p, df_sent_all) for p in error_p.glob(\"*disagree*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1badb6-8b5f-417e-8be9-541cbe24fefc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
